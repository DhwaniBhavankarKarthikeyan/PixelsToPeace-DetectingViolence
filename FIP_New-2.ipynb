{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "D7WJefFAaxRF",
        "xEBh1gTWgz_7",
        "uQNjstxuoomU",
        "N-HvmmNgtTkO",
        "FKuIszypuUal",
        "X9RihjJY11Uk",
        "hir1H3tH9Xqs",
        "Q1FO6WZHphK0",
        "wFKR51e7aiUJ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **“From Pixels to Peace : Detecting Violence”**"
      ],
      "metadata": {
        "id": "D7WJefFAaxRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8Ux6OEKgzqR",
        "outputId": "07192aff-fa0e-47ae-ea3f-438d63c9dd61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import all required libraries**"
      ],
      "metadata": {
        "id": "xEBh1gTWgz_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os"
      ],
      "metadata": {
        "id": "nuGsZeZHXdJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading both violent and non-violent video folders**"
      ],
      "metadata": {
        "id": "uQNjstxuoomU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "violent_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/Violence\"\n",
        "non_violent_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/Violence\""
      ],
      "metadata": {
        "id": "YB3lPVJTX7qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Enhancement of Violence**"
      ],
      "metadata": {
        "id": "N-HvmmNgtTkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Function for enhancing a frame\n",
        "def enhance_frame(frame):\n",
        "    # Convert the frame to grayscale\n",
        "    grayscale_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply histogram equalization for contrast enhancement\n",
        "    enhanced_frame = cv2.equalizeHist(grayscale_frame)\n",
        "    return enhanced_frame\n",
        "\n",
        "# Specify the path to the folder containing the videos\n",
        "violent_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/Violence\"\n",
        "\n",
        "# Create a folder to save the enhanced videos\n",
        "enhanced_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/Enhanced_Violence\"\n",
        "os.makedirs(enhanced_folder, exist_ok=True)\n",
        "\n",
        "# Process each video in the \"violent\" folder\n",
        "for video_file in os.listdir(violent_folder):\n",
        "    video_path = os.path.join(violent_folder, video_file)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Extract video properties\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Define the codec and create a VideoWriter to save the enhanced video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    enhanced_video_name = os.path.join(enhanced_folder, f\"enhanced_{video_file}\")\n",
        "    out = cv2.VideoWriter(enhanced_video_name, fourcc, fps, (width, height), isColor=False)  # Use isColor=False for grayscale video\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        enhanced_frame = enhance_frame(frame)\n",
        "\n",
        "        # Write the enhanced frame to the output video\n",
        "        out.write(enhanced_frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "print(\"Enhancement of videos complete.\")\n"
      ],
      "metadata": {
        "id": "y_jr_N_9tV4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Enhancement of Non-Violence**"
      ],
      "metadata": {
        "id": "FKuIszypuUal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Function for enhancing a frame\n",
        "def enhance_frame(frame):\n",
        "    # Convert the frame to grayscale\n",
        "    grayscale_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply histogram equalization for contrast enhancement\n",
        "    enhanced_frame = cv2.equalizeHist(grayscale_frame)\n",
        "    return enhanced_frame\n",
        "\n",
        "# Specify the path to the folder containing the videos\n",
        "violent_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/NonViolence\"\n",
        "\n",
        "# Create a folder to save the enhanced videos\n",
        "enhanced_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/Enhanced_NonViolence\"\n",
        "os.makedirs(enhanced_folder, exist_ok=True)\n",
        "\n",
        "# Process each video in the \"violent\" folder\n",
        "for video_file in os.listdir(violent_folder):\n",
        "    video_path = os.path.join(violent_folder, video_file)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Extract video properties\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Define the codec and create a VideoWriter to save the enhanced video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    enhanced_video_name = os.path.join(enhanced_folder, f\"enhanced_{video_file}\")\n",
        "    out = cv2.VideoWriter(enhanced_video_name, fourcc, fps, (width, height), isColor=False)  # Use isColor=False for grayscale video\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        enhanced_frame = enhance_frame(frame)\n",
        "\n",
        "        # Write the enhanced frame to the output video\n",
        "        out.write(enhanced_frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "print(\"Enhancement of videos complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdBl29x4ykzh",
        "outputId": "73de21df-8c77-4bfb-fe14-23a574b3a18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhancement of videos complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Denoising Enhanced Violence videos**"
      ],
      "metadata": {
        "id": "X9RihjJY11Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Function for denoising a frame\n",
        "def denoise_frame(frame):\n",
        "    # Apply a denoising filter (e.g., Gaussian blur)\n",
        "    denoised_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
        "    return denoised_frame\n",
        "\n",
        "# Specify the path to the folder containing the enhanced videos\n",
        "enhanced_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/Enhanced_Violence\"\n",
        "\n",
        "# Create a folder to save the denoised videos\n",
        "denoised_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/Denoised_Violence\"\n",
        "os.makedirs(denoised_folder, exist_ok=True)\n",
        "\n",
        "# Process each enhanced video in the \"enhanced\" folder\n",
        "for enhanced_video_file in os.listdir(enhanced_folder):\n",
        "    enhanced_video_path = os.path.join(enhanced_folder, enhanced_video_file)\n",
        "    cap = cv2.VideoCapture(enhanced_video_path)\n",
        "\n",
        "    # Extract video properties\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Check if the video is color or grayscale\n",
        "    is_color = int(cap.get(cv2.CAP_PROP_CONVERT_RGB))\n",
        "\n",
        "    # Define the codec and create a VideoWriter to save the denoised video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    denoised_video_name = os.path.join(denoised_folder, f\"denoised_{enhanced_video_file}\")\n",
        "    out = cv2.VideoWriter(denoised_video_name, fourcc, fps, (width, height), isColor=is_color)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        denoised_frame = denoise_frame(frame)\n",
        "\n",
        "        # Write the denoised frame to the output video\n",
        "        out.write(denoised_frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "print(\"Denoising of enhanced videos complete.\")\n"
      ],
      "metadata": {
        "id": "-q-VzAab164A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce74cf4-da36-45d0-f8ca-c583a25b76fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Denoising of enhanced videos complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Denoising Enhanced Non-Violence videos**"
      ],
      "metadata": {
        "id": "hir1H3tH9Xqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Function for denoising a frame\n",
        "def denoise_frame(frame):\n",
        "    # Apply a denoising filter (e.g., Gaussian blur)\n",
        "    denoised_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
        "    return denoised_frame\n",
        "\n",
        "# Specify the path to the folder containing the enhanced videos\n",
        "enhanced_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/Enhanced_NonViolence\"\n",
        "\n",
        "# Create a folder to save the denoised videos\n",
        "denoised_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/Denoised_Non-Violence\"\n",
        "os.makedirs(denoised_folder, exist_ok=True)\n",
        "\n",
        "# Process each enhanced video in the \"enhanced\" folder\n",
        "for enhanced_video_file in os.listdir(enhanced_folder):\n",
        "    enhanced_video_path = os.path.join(enhanced_folder, enhanced_video_file)\n",
        "    cap = cv2.VideoCapture(enhanced_video_path)\n",
        "\n",
        "    # Extract video properties\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Check if the video is color or grayscale\n",
        "    is_color = int(cap.get(cv2.CAP_PROP_CONVERT_RGB))\n",
        "\n",
        "    # Define the codec and create a VideoWriter to save the denoised video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    denoised_video_name = os.path.join(denoised_folder, f\"denoised_{enhanced_video_file}\")\n",
        "    out = cv2.VideoWriter(denoised_video_name, fourcc, fps, (width, height), isColor=is_color)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        denoised_frame = denoise_frame(frame)\n",
        "\n",
        "        # Write the denoised frame to the output video\n",
        "        out.write(denoised_frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "print(\"Denoising of enhanced videos complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76dddadf-5183-4ec1-fbdc-6d5f3d2fbe4d",
        "id": "I-fX6cw29eeE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Denoising of enhanced videos complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Segmentation and feature extraction**"
      ],
      "metadata": {
        "id": "Q1FO6WZHphK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Function for segmenting objects using thresholding\n",
        "def segment_objects(frame):\n",
        "    # Convert the frame to grayscale\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply a threshold to separate objects from the background\n",
        "    _, thresholded = cv2.threshold(gray_frame, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    return thresholded\n",
        "\n",
        "# Function for feature extraction (color histogram for a grayscale image)\n",
        "def extract_features(segmented_frame):\n",
        "    # Calculate the histogram of the segmented region (use [0] for the single channel)\n",
        "    hist = cv2.calcHist([segmented_frame], [0], None, [256], [0, 256])\n",
        "\n",
        "    # Normalize the histogram\n",
        "    hist = cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "    return hist\n",
        "\n",
        "# Specify the paths to the folders containing videos (violent and non-violent)\n",
        "violent_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/Denoised_Violence\"\n",
        "non_violent_folder = \"/content/drive/MyDrive/FIP_Project/Real Life Violence Dataset/Denoised_Non-Violence\"\n",
        "\n",
        "# Create lists to store extracted features\n",
        "violent_features = []\n",
        "non_violent_features = []\n",
        "\n",
        "# Function to process videos in a folder\n",
        "def process_videos_in_folder(folder, features_list):\n",
        "    for video_file in os.listdir(folder):\n",
        "        video_path = os.path.join(folder, video_file)\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Apply segmentation to the frame\n",
        "            segmented_frame = segment_objects(frame)\n",
        "\n",
        "            # Extract features from the segmented region\n",
        "            features = extract_features(segmented_frame)\n",
        "\n",
        "            features_list.append(features)\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "# Process violent videos\n",
        "process_videos_in_folder(violent_folder, violent_features)\n",
        "\n",
        "# Process non-violent videos\n",
        "process_videos_in_folder(non_violent_folder, non_violent_features)\n",
        "\n",
        "# Now, you have extracted features for both violent and non-violent videos\n",
        "# You can use these features for event classification or any other analysis\n",
        "\n",
        "print(\"Feature extraction complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23vKZrMepkuF",
        "outputId": "f178f791-0d6a-4d94-b51c-32b45bbe1572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Model Training and Testing**"
      ],
      "metadata": {
        "id": "wFKR51e7aiUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Combine features and labels\n",
        "X = violent_features + non_violent_features\n",
        "y = [1] * len(violent_features) + [0] * len(non_violent_features)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Create and train a Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_val_pred = clf.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "report = classification_report(y_val, y_val_pred)\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Evaluate the model on the test set for final evaluation\n",
        "y_test_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_test_pred)\n",
        "report = classification_report(y_test, y_test_pred)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Classification Report (Test):\\n\", report)\n"
      ],
      "metadata": {
        "id": "6wbGrDH7p5Om",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96d1d6b-f188-4795-d1fd-31dbd1518c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.7457139542976453\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.79      0.73     19189\n",
            "           1       0.81      0.71      0.76     23916\n",
            "\n",
            "    accuracy                           0.75     43105\n",
            "   macro avg       0.75      0.75      0.75     43105\n",
            "weighted avg       0.75      0.75      0.75     43105\n",
            "\n",
            "Test Accuracy: 0.7508931471256901\n",
            "Classification Report (Test):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.79      0.74     19203\n",
            "           1       0.81      0.72      0.76     23903\n",
            "\n",
            "    accuracy                           0.75     43106\n",
            "   macro avg       0.75      0.75      0.75     43106\n",
            "weighted avg       0.76      0.75      0.75     43106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T01WvOkHp0Io"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}